{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alice in Wonderland Hyperdictionary Prediction\n",
    "\n",
    "I am creating a pipeline for testing predictions. I am going to compare different strategies and try and predict the next letter given a sentence from alice and 20 characters within that sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import random_idx\n",
    "import utils\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdict = open(\"raw_texts/texts_english/alice_in_wonderland.txt\")\n",
    "text = fdict.read()\n",
    "\n",
    "sentences = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1207"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the function to run the test. This takes in a prediction function, gives it a sentence and asks the function to predict the next letter. Right now, I have the prediction_func return a histogram of letters, but the test_prediction just takes the maximum. Guy was talking about measuring entropy reduction, which is probably a better metric, but this is just a first pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_prediction(prediction_func, lookback=20):\n",
    "    \n",
    "    # We're doing all this just to make sure the sentence is long enough\n",
    "    for i in range(100):\n",
    "        sidx = np.random.randint(lookback)\n",
    "        sentence_str = sentences[np.random.randint(len(sentences))].lower()\n",
    "        \n",
    "        rm = string.punctuation + string.digits\n",
    "    \n",
    "        for p in string.punctuation:\n",
    "            sentence_str = sentence_str.replace(p, '')\n",
    "        \n",
    "        sentence_str = sentence_str.replace('\\n',' ')\n",
    "        sentence_str = sentence_str.replace('\\r','')\n",
    "        sentence_str = sentence_str.replace('\\t','')\n",
    "        sentence_str = sentence_str.strip()\n",
    "        \n",
    "        if len(sentence_str[sidx:]) > lookback:\n",
    "            break\n",
    "            \n",
    "\n",
    "    \n",
    "    # ok, so ask for the next letter\n",
    "    next_letter_dist = prediction_func(sentence_str[:lookback])\n",
    "    \n",
    "    # just take the argmax for now.\n",
    "    pred_lidx = np.argmax(next_letter_dist)\n",
    "    \n",
    "    corr_letter = sentence_str[lookback]\n",
    "    corr_lidx = random_idx.alphabet.find(corr_letter)\n",
    "    \n",
    "    # output to analyze performance\n",
    "    print sentence_str[:lookback], random_idx.alphabet[corr_lidx], random_idx.alphabet[pred_lidx]\n",
    "    \n",
    "    return corr_lidx == pred_lidx\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always Guess 'e'\n",
    "\n",
    "The first thing to try is to just guess 'e' every time. Let's see how that does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def always_predict_e(sentence):\n",
    "    letter_hist = zeros(len(random_idx.alphabet))\n",
    "    \n",
    "    letter_hist[4] = 1\n",
    "    \n",
    "    return letter_hist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at this moment the k i e\n",
      "the cook threw a fry i e\n",
      "hand it over here sa i e\n",
      "dont grunt said alic e e\n",
      "when she got back to   e\n",
      "its enough to drive  o e\n",
      "they all made a rush   e\n",
      "if the second copy i s e\n",
      "they cant have anyth i e\n",
      "then they all crowde d e\n",
      "if you are redistrib u e\n",
      "if you received the  w e\n",
      "tell her about the r e e\n",
      "as a duck with its e y e\n",
      "all the time they we r e\n",
      "there was no one two   e\n",
      "now at ours they had   e\n",
      "well thought alice t o e\n",
      "it quite makes my fo r e\n",
      "as if it wasnt troub l e\n",
      "write that down the  k e\n",
      "there are a few thin g e\n",
      "the jury all brighte n e\n",
      "id rather finish my  t e\n",
      "so she set to work a n e\n",
      "how can i have done  t e\n",
      "the trial cannot pro c e\n",
      "youre a very poor sp e e\n",
      "they were just begin n e\n",
      "the three soldiers w a e\n",
      "if everybody minded  t e\n",
      "it exists because of   e\n",
      "why there they are s a e\n",
      "dinahll miss me very   e\n",
      "if youre going to tu r e\n",
      "in another minute th e e\n",
      "alice said nothing s h e\n",
      "they very soon came  u e\n",
      "the reason is said t h e\n",
      "unless you have remo v e\n",
      "oh dont talk about t r e\n",
      "well i never heard i t e\n",
      "now ill manage bette r e\n",
      "when we were little  t e\n",
      "the door led right i n e\n",
      "shall i try the expe r e\n",
      "ten hours the first  d e\n",
      "it was the best butt e e\n",
      "i believe so alice r e e\n",
      "but perhaps he cant  h e\n",
      "the poor little thin g e\n",
      "despite these effort s e\n",
      "and washing said the   e\n",
      "perhaps it hasnt one   e\n",
      "theres a great deal  t e\n",
      "you grant that  i su p e\n",
      "i havent opened it y e e\n",
      "not the same thing a   e\n",
      "the first thing she  h e\n",
      "the first thing she  h e\n",
      "at last the dodo sai d e\n",
      "if id been the whiti n e\n",
      "so long as i get som e e\n",
      "how fond she is of f i e\n",
      "then againbefore she   e\n",
      "you ought to be asha m e\n",
      "but im not used to i t e\n",
      "how are you getting  o e\n",
      "im afraid i cant put   e\n",
      "first came ten soldi e e\n",
      "the master was an ol d e\n",
      "alice did not much l i e\n",
      "ill fetch the execut i e\n",
      "and she squeezed her s e\n",
      "the poor little liza r e\n",
      "if you dont know wha t e\n",
      "let me alone  serpen t e\n",
      "the queens argument  w e\n",
      "first it marked out  a e\n",
      "well it must be remo v e\n",
      "it was this last rem a e\n",
      "the hatter was the f i e\n",
      "who is it directed t o e\n",
      "she felt that she wa s e\n",
      "contributions to the   e\n",
      "im afraid i cant put   e\n",
      "alice remained looki n e\n",
      "when im a duchess sh e e\n",
      "there was a sound of   e\n",
      "they had a large can v e\n",
      "shall we try another   e\n",
      "then the dormouse sh a e\n",
      "ive so often read in   e\n",
      "not at all said alic e e\n",
      "i mean what makes th e e\n",
      "let me see that woul d e\n",
      "alice thought she ha d e\n",
      "it was this last rem a e\n",
      "here was another puz z e\n",
      "theyre putting down  t e\n",
      "0.12\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "iscorrect_prediction = zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "    iscorrect_prediction[i] = test_prediction(always_predict_e)\n",
    "    \n",
    "print np.mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can get about 10-15% of the next letter guesses correct by just guessing 'e' every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Dictionary\n",
    "\n",
    "A pretty sensible method of predicting the next letter is to use an external dictionary and try and base the guess on the last word. This external dictionary is created from the '2of12id.txt' dictionary, but only contains a subset of the full word list. This dictionary also includes every substring of the word, as well as spaces -- the full word contains a space at the end. This way it can guess space. This dictionary is naive to any of the statistics of the word appearance, and will just guess based on what is possible and not what is most likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.load('data/hyperdictionary_external-s20-d1M-160223.npz')\n",
    "letter_vectors_substr = h['letter_vectors']\n",
    "hyperdictionary_substr = h['hyperdictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either the well was  v t\n",
      "id rather finish my  t s\n",
      "please check the pro j f\n",
      "do not copy display  p f\n",
      "so they sat down and   a\n",
      "that you wont though t a\n",
      "next came the guests   k\n",
      "it tells the day of  t t\n",
      "there was a general  c i\n",
      "she cant explain it  s a\n",
      "and just as id taken   y\n",
      "the foundations prin c c\n",
      "ive tried the roots  o b\n",
      "silence all round if   r\n",
      "in a minute or two t h a\n",
      "we wont talk about h e u\n",
      "creating the works f r i\n",
      "begin at the beginni n n\n",
      "not quite right im a f n\n",
      "with extras asked th e r\n",
      "i can tell you more  t  \n",
      "i cant go no lower s a c\n",
      "there could be no do u w\n",
      "when we were little  t  \n",
      "it was no doubt only   r\n",
      "alice felt that this   g\n",
      "here the other guine a k\n",
      "ah then yours wasnt  a m\n",
      "the miserable hatter   o\n",
      "come lets try the fi r l\n",
      "you must remember re m m\n",
      "just think of what w o e\n",
      "hearthrug          n e i\n",
      "its really dreadful  s n\n",
      "off with her head th e r\n",
      "will you wont you wi l c\n",
      "oh dear what nonsens e u\n",
      "first because im on  t t\n",
      "the reason is said t h a\n",
      "why what are your sh o u\n",
      "i cant go no lower s a c\n",
      "well perhaps your fe e m\n",
      "do not copy display  p f\n",
      "we called him tortoi s s\n",
      "it must be a very pr e i\n",
      "i call it purring no t m\n",
      "the door led right i n l\n",
      "you are old said the   i\n",
      "do not charge a fee  f d\n",
      "alice said nothing s h c\n",
      "you may copy it give   s\n",
      "when did you begin   t n\n",
      "now at ours they had   o\n",
      "he sent them word i  h l\n",
      "the cat seemed to th i r\n",
      "you must be said the   i\n",
      "after a minute or tw o i\n",
      "this time alice wait e s\n",
      "it was this last rem a e\n",
      "how could he turn th e r\n",
      "the idea of having t h a\n",
      "why said the dodo th e r\n",
      "and she began thinki n k\n",
      "take off your hat th e r\n",
      "she cant explain it  s a\n",
      "i can tell you more  t  \n",
      "the mock turtles sto r p\n",
      "come on  so they wen t d\n",
      "limited warranty dis c g\n",
      "it isnt said the cat e s\n",
      "oh dear what nonsens e u\n",
      "it isnt said the cat e s\n",
      "i dont quite underst a a\n",
      "turn a somersault in   l\n",
      "nothing whatever sai d l\n",
      "it is a long tail ce r m\n",
      "now i growl when im  p p\n",
      "information about th e r\n",
      "there are a few thin g g\n",
      "what are you thinkin g m\n",
      "alice thought the wh o a\n",
      "project gutenberg is   s\n",
      "theyre putting down  t s\n",
      "stuff and nonsense s a c\n",
      "youre wrong about th e r\n",
      "and washing said the   i\n",
      "shall we try another   k\n",
      "presently the rabbit   l\n",
      "will you wont you wi l c\n",
      "change lobsters agai n b\n",
      "while she was lookin g a\n",
      "she cant explain it  s a\n",
      "you grant that  i su p n\n",
      "creating the works f r i\n",
      "it was this last rem a e\n",
      "it was much pleasant e r\n",
      "the judge by the way    \n",
      "they cant have anyth i i\n",
      "i wasnt asleep he sa i i\n",
      "in which the cook an d g\n",
      "0.12\n"
     ]
    }
   ],
   "source": [
    "N = hyperdictionary_substr.shape[0]\n",
    "\n",
    "def predict_from_last_word(sentence):\n",
    "    # find the last space in the sentence\n",
    "    words = sentence.split()\n",
    "    \n",
    "    last_word = words[-1]    \n",
    "    \n",
    "    subword = ''\n",
    "    subvec = np.ones(N)\n",
    "    for i,letter in enumerate(last_word):\n",
    "        letter_idx = random_idx.alphabet.find(letter)\n",
    "        subvec = np.roll(subvec, 1) * letter_vectors_substr[letter_idx,:]\n",
    "        subword += letter\n",
    "        \n",
    "    subvec = np.roll(subvec, 1)\n",
    "    \n",
    "    val = np.dot(letter_vectors_substr/N, subvec*hyperdictionary_substr)\n",
    "    return val\n",
    "\n",
    "        \n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary is pretty close performance-wise to just guessing 'e'. However, you can see it does a decent job when there is a long word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using internal hyperdictionary\n",
    "\n",
    "Next, I built a similar substring hyperdictionary as before, but this time I used the list of words actually from alice. This is a pretty ideal dictionary to have handy. The performance of this dictionary is useful to compare with other algorithms, as this will have a good chance of working well. If another algorithm can beat this, then it has learned a lot about english and predicting Alice, and probably has an important insight about learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.load('data/hyperdictionary_alice-d1M-160223.npz')\n",
    "letter_vectors_alice = h['letter_vectors']\n",
    "hyperdictionary_alice = h['hyperdictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come            ill  t  \n",
      "alice did not much l i a\n",
      "then the dormouse sh a i\n",
      "very true said the d u r\n",
      "on which seven looke d d\n",
      "you dont know much s a l\n",
      "would you tell me pl e e\n",
      "a knot said alice al w l\n",
      "are youare you fondo f f\n",
      "alice noticed with s o l\n",
      "indeed she had quite    \n",
      "a cat may look at a  k m\n",
      "anything you like sa i i\n",
      "on this the white ra b p\n",
      "im sure im not ada s h l\n",
      "he unfolded the pape r r\n",
      "there was no label t h  \n",
      "the hedgehog was eng a l\n",
      "as a duck with its e y d\n",
      "for instance suppose    \n",
      "so they got their ta i k\n",
      "collar that dormouse    \n",
      "org  for additional  c  \n",
      "he was an old crab h e j\n",
      "thats nothing to wha t t\n",
      "we quarrelled last m a o\n",
      "please maam is this  n  \n",
      "alice began to feel  v  \n",
      "i hope theyll rememb e e\n",
      "it looked goodnature d f\n",
      "i could tell you my  a s\n",
      "it was no doubt only    \n",
      "ten hours the first  d  \n",
      "the jury all looked  p  \n",
      "they couldnt have do n i\n",
      "he took me for his h o j\n",
      "there are a lot of t h  \n",
      "its no use speaking  t  \n",
      "begin at the beginni n n\n",
      "a knot said alice al w l\n",
      "we must burn the hou s r\n",
      "but youre so easily  o  \n",
      "how could he turn th e e\n",
      "first it marked out  a s\n",
      "lets go on with the  g m\n",
      "shed soon fetch it b a u\n",
      "then you keep moving    \n",
      "at last the gryphon  s  \n",
      "a cat may look at a  k m\n",
      "the knave shook his  h t\n",
      "will you wont you wi l d\n",
      "ive seen hatters bef o o\n",
      "they lived on treacl e e\n",
      "most people start at    \n",
      "then she went to wor k k\n",
      "then you may sit dow n n\n",
      "who are you talking  t  \n",
      "are their heads off  s  \n",
      "it is a long tail ce r r\n",
      "fetch me my gloves t h  \n",
      "and the moral of tha t n\n",
      "and now which is whi c t\n",
      "but she must have a  p m\n",
      "so long as i get som e e\n",
      "the following senten c c\n",
      "how surprised hell b e u\n",
      "as soon as she was s m l\n",
      "but who is to give t h  \n",
      "oh do let me help to   r\n",
      "i mean what i say th e e\n",
      "please come back and    \n",
      "the knave shook his  h t\n",
      "oh dont talk about t r  \n",
      "ill put a stop to th i e\n",
      "information about th e e\n",
      "i wasnt asleep he sa i i\n",
      "you said the caterpi l l\n",
      "it quite makes my fo r r\n",
      "tis so said the duch e e\n",
      "now we shall get on  b l\n",
      "thats nothing to wha t t\n",
      "come on  so they wen t t\n",
      "twinkle twinkle  her e  \n",
      "newby      chief exe c m\n",
      "then you know the mo c n\n",
      "i dont know of any t h  \n",
      "come theres half my  p s\n",
      "behead that dormouse    \n",
      "of course it is said    \n",
      "dont talk nonsense s a l\n",
      "dinahll miss me very    \n",
      "so long as i get som e e\n",
      "i dont see said the  c m\n",
      "he denies it said th e e\n",
      "if you are redistrib u u\n",
      "an enormous puppy wa s t\n",
      "creating the works f r e\n",
      "get up said the quee n r\n",
      "of course you dont t h  \n",
      "mine is a long and a   m\n",
      "0.37\n"
     ]
    }
   ],
   "source": [
    "N = hyperdictionary_alice.shape[0]\n",
    "\n",
    "def predict_from_last_word(sentence):\n",
    "    \n",
    "    if sentence[-1] == ' ':\n",
    "        letter_hist = zeros(len(random_idx.alphabet))\n",
    "        # guess 't' if it is a space at the end\n",
    "        t_idx = random_idx.alphabet.find('t')\n",
    "        letter_hist[t_idx] = 1\n",
    "        return letter_hist\n",
    "    else:\n",
    "        # find the last space in the sentence\n",
    "        words = sentence.split()\n",
    "\n",
    "        last_word = words[-1]    \n",
    "\n",
    "        subword = ''\n",
    "        subvec = np.ones(N)\n",
    "        for i,letter in enumerate(last_word):\n",
    "            letter_idx = random_idx.alphabet.find(letter)\n",
    "            subvec = np.roll(subvec, 1) * letter_vectors_alice[letter_idx,:]\n",
    "            subword += letter\n",
    "\n",
    "        subvec = np.roll(subvec, 1)\n",
    "\n",
    "        val = np.dot(letter_vectors_alice/N, subvec*hyperdictionary_alice)\n",
    "        return val\n",
    "\n",
    "        \n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you didnt sign it   s\n",
      "i should like to hea r p\n",
      "1 with active links  o  \n",
      "you insult me by tal k l\n",
      "oh i beg your pardon   e\n",
      "there was nothing el s b\n",
      "he moved on as he sp o i\n",
      "so she began again o u l\n",
      "i dont know of any t h  \n",
      "treacle said a sleep y  \n",
      "go on with the next  v  \n",
      "only mustard isnt a  b m\n",
      "alice replied rather    \n",
      "but her sister sat s t l\n",
      "ive seen hatters bef o o\n",
      "the gryphon replied  v  \n",
      "dont grunt said alic e e\n",
      "the jury all brighte n n\n",
      "if the second copy i s m\n",
      "so alice got up and  r  \n",
      "the poor little thin g g\n",
      "turn a somersault in   j\n",
      "what trial is it ali c c\n",
      "for with all her kno w t\n",
      "i hope theyll rememb e e\n",
      "you are old said the   m\n",
      "except for the limit e e\n",
      "there was a sound of    \n",
      "a cheap sort of pres e s\n",
      "royalty payments sho u w\n",
      "they cant have anyth i i\n",
      "no i didnt said alic e e\n",
      "get up said the quee n r\n",
      "why  it does the boo t k\n",
      "you may copy it give   n\n",
      "it was high time to  g r\n",
      "contact the foundati o o\n",
      "this piece of rudene s s\n",
      "i dont know the mean i w\n",
      "it must be a very pr e a\n",
      "i dont know of any t h  \n",
      "i dare say you never    \n",
      "their heads are gone    \n",
      "i thought you did sa i i\n",
      "org111    updated ed i u\n",
      "why not said the mar c c\n",
      "fetch me my gloves t h  \n",
      "then they all crowde d d\n",
      "why what are your sh o i\n",
      "wake up alice dear s a l\n",
      "how queer it seems a l m\n",
      "but do cats eat bats    \n",
      "you agree that the f o e\n",
      "she stretched hersel f f\n",
      "alice went timidly u p p\n",
      "the project gutenber g g\n",
      "i dare say youre won d t\n",
      "first she tried to l o a\n",
      "in a minute or two t h  \n",
      "by reading or using  a  \n",
      "there was certainly  t  \n",
      "you must require suc h c\n",
      "are their heads off  s  \n",
      "i beg your pardon sa i i\n",
      "this did not seem to   r\n",
      "first however she wa i t\n",
      "the king looked anxi o o\n",
      "its enough to drive  o  \n",
      "and she squeezed her s  \n",
      "this was such a new  i  \n",
      "if everybody minded  t  \n",
      "just think of what w o a\n",
      "but im not used to i t m\n",
      "when she got back to   r\n",
      "he moved on as he sp o i\n",
      "in another moment do w i\n",
      "it began with the te a n\n",
      "the hatter shook his   t\n",
      "but if im not the sa m i\n",
      "so alice began telli n n\n",
      "is that the reason s o l\n",
      "an enormous puppy wa s t\n",
      "there isnt any said  t  \n",
      "did you say what a p i l\n",
      "please come back and    \n",
      "i wonder what theyll    \n",
      "write that down the  k m\n",
      "hart is the originat o o\n",
      "suddenly she came up o d\n",
      "i mean what makes th e e\n",
      "and be quick about i t m\n",
      "will you wont you wi l d\n",
      "if youre going to tu r c\n",
      "she had already hear d t\n",
      "there was a sound of    \n",
      "the next thing was t o  \n",
      "this was such a new  i  \n",
      "this time there were   n\n",
      "who cares for you sa i i\n",
      "after a minute or tw o e\n",
      "0.31\n"
     ]
    }
   ],
   "source": [
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you dont know much s a l\n",
      "if i dont take this  c t\n",
      "limited right of rep l o\n",
      "it quite makes my fo r r\n",
      "do not charge a fee  f t\n",
      "same as if he had a  b t\n",
      "what is a caucusrace   l\n",
      "down the rabbithole    t\n",
      "and the gryphon neve r r\n",
      "its a friend of mine a  \n",
      "it was much pleasant e  \n",
      "i dont know the mean i w\n",
      "call it what you lik e e\n",
      "next came an angry v o u\n",
      "if you do not agree  t t\n",
      "i havent opened it y e a\n",
      "have you guessed the   m\n",
      "theres plenty of roo m t\n",
      "or would you like th e e\n",
      "im glad they dont gi v r\n",
      "give your evidence t h  \n",
      "itsits a very fine d a r\n",
      "here was another puz z z\n",
      "now i give you fair  w t\n",
      "it quite makes my fo r r\n",
      "how fond she is of f i e\n",
      "bythebye what became    \n",
      "the end      end of  p t\n",
      "compliance requireme n n\n",
      "i wonder what i shou l t\n",
      "do you mean that you   t\n",
      "how surprised hell b e u\n",
      "the king laid his ha n i\n",
      "alice was just begin n  \n",
      "why said the dodo th e e\n",
      "she was walking by t h  \n",
      "to learn more about  t t\n",
      "turn a somersault in   j\n",
      "you dont know much s a l\n",
      "this time alice wait e i\n",
      "at last the gryphon  s t\n",
      "here one of the guin e e\n",
      "oh youre sure to do  t t\n",
      "alice waited a littl e e\n",
      "come back the caterp i i\n",
      "at any rate ill neve r r\n",
      "the queens argument  w t\n",
      "are youare you fondo f f\n",
      "give your evidence s a l\n",
      "alice was very nearl y y\n",
      "that was a narrow es c q\n",
      "and washing said the   m\n",
      "compliance requireme n n\n",
      "which he certainly d i r\n",
      "you must remember re m v\n",
      "just then she heard  s t\n",
      "they all can said th e e\n",
      "how she longed to ge t o\n",
      "she got up and went  t t\n",
      "if you do not charge   s\n",
      "i call it purring no t r\n",
      "of course you dont t h  \n",
      "when she got back to   r\n",
      "but she must have a  p t\n",
      "one of the jurors ha d i\n",
      "but the insolence of    \n",
      "wouldnt it really sa i i\n",
      "many small donations    \n",
      "this time alice wait e i\n",
      "i keep them to sell  t t\n",
      "stuff and nonsense s a l\n",
      "ive a right to think   i\n",
      "they have their tail s s\n",
      "oh i beg your pardon   e\n",
      "its 501c3 letter is  p t\n",
      "the lobster quadrill e e\n",
      "but its no use now t h  \n",
      "the master was an ol d d\n",
      "why said the dodo th e e\n",
      "treacle said the dor m m\n",
      "let me see four time s s\n",
      "so they couldnt get  t t\n",
      "where shall i begin  p t\n",
      "the question is what   e\n",
      "he had been looking  a t\n",
      "and so it was indeed    \n",
      "come            ill  t t\n",
      "did you say pig or f i e\n",
      "in another moment do w i\n",
      "then followed the kn a i\n",
      "you provide a full r e o\n",
      "i know what it means    \n",
      "well thought alice t o  \n",
      "how are you getting  o t\n",
      "the fishfootman bega n n\n",
      "come thats a good th i e\n",
      "she soon got it out  a t\n",
      "they were learning t o  \n",
      "you dont know much s a l\n",
      "it may only be used  o t\n",
      "0.36\n"
     ]
    }
   ],
   "source": [
    "N = hyperdictionary_alice.shape[0]\n",
    "\n",
    "def predict_from_last_word(sentence):\n",
    "    \n",
    "    if sentence[-1] == ' ':\n",
    "        letter_hist = zeros(len(random_idx.alphabet))\n",
    "        # guess 't' if it is a space at the end\n",
    "        t_idx = random_idx.alphabet.find('t')\n",
    "        letter_hist[t_idx] = 1\n",
    "        return letter_hist\n",
    "    else:\n",
    "        # find the last space in the sentence\n",
    "        words = sentence.split()\n",
    "\n",
    "        last_word = words[-1]    \n",
    "\n",
    "        subword = ''\n",
    "        subvec = np.ones(N)\n",
    "        for i,letter in enumerate(last_word):\n",
    "            letter_idx = random_idx.alphabet.find(letter)\n",
    "            subvec = np.roll(subvec, 1) * letter_vectors_alice[letter_idx,:]\n",
    "            subword += letter\n",
    "\n",
    "        subvec = np.roll(subvec, 1)\n",
    "\n",
    "        val = np.dot(letter_vectors_alice/N, subvec*hyperdictionary_alice)\n",
    "        return val\n",
    "\n",
    "        \n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you ought to be asha m m\n",
      "it proves nothing of    \n",
      "what is a caucusrace   l\n",
      "they lived on treacl e e\n",
      "how can i have done  t t\n",
      "a cheap sort of pres e s\n",
      "so she began o mouse    \n",
      "no please go on alic e e\n",
      "is that the reason s o l\n",
      "alice knew it was th e e\n",
      "once upon a time the r m\n",
      "well i never heard i t m\n",
      "and he added in an u n p\n",
      "alice did not feel e n d\n",
      "my notion was that y o a\n",
      "it was the best butt e o\n",
      "im a poor man your m a o\n",
      "she had already hear d t\n",
      "you must have meant  s t\n",
      "but perhaps he cant  h t\n",
      "when the pie was all    \n",
      "its business office  i t\n",
      "so she set to work a n m\n",
      "you may charge a rea s r\n",
      "it is a long tail ce r r\n",
      "get up said the quee n r\n",
      "i do alice hastily r e o\n",
      "thats none of your b u u\n",
      "alice looked at the  j t\n",
      "that i cant remember   e\n",
      "come back the caterp i i\n",
      "and she squeezed her s  \n",
      "thats the most impor t t\n",
      "the table was a larg e e\n",
      "wow wow wow  here yo u u\n",
      "orgdonate   section    t\n",
      "then the words dont  f t\n",
      "no theyre not said t h  \n",
      "dont grunt said alic e e\n",
      "why what are your sh o i\n",
      "i dare say you never    \n",
      "the cat seemed to th i e\n",
      "org  this web site i n m\n",
      "and where have my sh o i\n",
      "alice was not a bit  h t\n",
      "you insult me by tal k l\n",
      "stand up and repeat  t t\n",
      "the poor little thin g g\n",
      "the reason is said t h  \n",
      "she is such a dear q u u\n",
      "im sure im not ada s h l\n",
      "that i cant remember   e\n",
      "of course they were  s t\n",
      "alice said nothing s h l\n",
      "bythebye what became    \n",
      "youll see me there s a l\n",
      "consider your verdic t t\n",
      "you agree that the f o e\n",
      "they were learning t o  \n",
      "that would be grand  c t\n",
      "what is it  the gryp h h\n",
      "which he certainly d i r\n",
      "the only things in t h  \n",
      "you must require suc h c\n",
      "wow wow wow  here yo u u\n",
      "at last the gryphon  s t\n",
      "and he got up very s u l\n",
      "creating the works f r e\n",
      "im not a serpent sai d d\n",
      "and washing said the   m\n",
      "information about th e e\n",
      "alice waited till th e e\n",
      "the fishfootman bega n n\n",
      "the first thing she  h t\n",
      "its a pun the king a d m\n",
      "do you know why its  c t\n",
      "behead that dormouse    \n",
      "it must have been th a e\n",
      "and just take his he a i\n",
      "how she longed to ge t o\n",
      "org   title alices a d m\n",
      "the next thing was t o  \n",
      "you might just as we l  \n",
      "thats very important    \n",
      "alice thought she ha d i\n",
      "if you knew time as  w t\n",
      "on which seven looke d d\n",
      "if youre going to tu r c\n",
      "one side of what the   m\n",
      "and yet i dont know  h t\n",
      "there isnt any said  t t\n",
      "there are a few thin g g\n",
      "so she swallowed one    \n",
      "i think that will be   h\n",
      "please your majesty  s t\n",
      "there is another sho r w\n",
      "alice folded her han d d\n",
      "collar that dormouse    \n",
      "would not could not  w t\n",
      "an invitation for th e e\n",
      "0.36\n"
     ]
    }
   ],
   "source": [
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using N-Grams for prediction\n",
    "\n",
    "So, now I made dictionaries that go through the alice text and look at all n-grams, including 'space' as a character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = np.load('data/alice-2gram-space-d10K-160223.npz')\n",
    "letter_vectors_2g = h['letter_vectors']\n",
    "hyperdictionary_2g = np.squeeze(h['hyperdictionary'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = hyperdictionary_2g.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pray dont trouble yo u u\n",
      "it turned into a pig    \n",
      "do not copy display  p t\n",
      "the unfortunate litt l h\n",
      "alice kept her eyes  a t\n",
      "you couldnt have wan t  \n",
      "it quite makes my fo r u\n",
      "there are a few thin g  \n",
      "the chief difficulty    \n",
      "whos making personal   i\n",
      "alice waited till th e e\n",
      "i told you butter wo u u\n",
      "and ever since that  t t\n",
      "in the very middle o f u\n",
      "however it was over  a t\n",
      "3 a full refund of a n n\n",
      "you may copy it give    \n",
      "i dont know where di n n\n",
      "there are a few thin g  \n",
      "theres more evidence    \n",
      "however she got up a n n\n",
      "she is such a dear q u  \n",
      "3 the project gutenb e e\n",
      "so they began solemn l  \n",
      "if you paid a fee fo r u\n",
      "and she went on plan n  \n",
      "dont let him know sh e e\n",
      "we wont talk about h e e\n",
      "first it marked out  a t\n",
      "so long as i get som e e\n",
      "it was this last rem a e\n",
      "if i dont take this  c t\n",
      "i thought you did sa i n\n",
      "the poor little thin g  \n",
      "presently the rabbit   h\n",
      "she had just succeed e  \n",
      "but its volunteers a n n\n",
      "here was another puz z y\n",
      "he looked anxiously  o t\n",
      "do you mean that you   t\n",
      "does the boots and s h  \n",
      "exactly so said the  h t\n",
      "up lazy thing said t h h\n",
      "alice waited till th e e\n",
      "oh my poor little fe e  \n",
      "the kings argument w a a\n",
      "see how eagerly the  l t\n",
      "that proves his guil t i\n",
      "i shall sit here the    \n",
      "it must be a very pr e  \n",
      "give your evidence s a  \n",
      "alice kept her eyes  a t\n",
      "stuff and nonsense s a  \n",
      "please then said ali c n\n",
      "shy they seem to put   h\n",
      "general information  a t\n",
      "donations are accept e h\n",
      "stolen the king excl a i\n",
      "her listeners were p e l\n",
      "shed soon fetch it b a e\n",
      "i dont see said the  c t\n",
      "the three soldiers w a a\n",
      "have some wine the m a e\n",
      "i can tell you more  t t\n",
      "here come and help m e e\n",
      "i dont believe it sa i n\n",
      "a nice muddle their  s t\n",
      "first because im on  t t\n",
      "you did said the hat t h\n",
      "i dont believe it sa i n\n",
      "that would be grand  c t\n",
      "very much indeed sai d n\n",
      "of the mushroom said    \n",
      "what is the fun said    \n",
      "you advance twice  e a  \n",
      "at last the dodo sai d n\n",
      "now tell me pat what s h\n",
      "i cant go no lower s a  \n",
      "i wonder what i shou l t\n",
      "turn a somersault in    \n",
      "so you see miss were    \n",
      "to send donations or    \n",
      "i heard the queen sa y n\n",
      "what fun said the gr y  \n",
      "any alternate format   h\n",
      "begin at the beginni n n\n",
      "up lazy thing said t h h\n",
      "most people start at   h\n",
      "an enormous puppy wa s n\n",
      "the fee is      owed    \n",
      "just about as much r i  \n",
      "but who is to give t h h\n",
      "this did not seem to   u\n",
      "one of the jurors ha d n\n",
      "volunteers and finan c  \n",
      "ive something import a h\n",
      "org   title alices a d n\n",
      "but do cats eat bats    \n",
      "alice thought she mi g n\n",
      "the mock turtles sto r u\n",
      "0.34\n"
     ]
    }
   ],
   "source": [
    "def predict_from_2grams(sentence):\n",
    "    letter = sentence[-1]\n",
    "    subvec = np.ones(N)\n",
    "    \n",
    "    letter_idx = random_idx.alphabet.find(letter)\n",
    "    subvec = np.roll(subvec, 1) * letter_vectors_2g[letter_idx,:]\n",
    "    subvec = np.roll(subvec, 1)\n",
    "\n",
    "    val = np.dot(letter_vectors_2g/N, subvec*hyperdictionary_2g)\n",
    "    \n",
    "    return val\n",
    "\n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_2grams)\n",
    "       \n",
    "print mean(iscorrect_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the 2-grams works fairly well. We can just see what it will predict for each letter, since it is only based on the last letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a n\n",
      "b e\n",
      "c h\n",
      "d  \n",
      "e  \n",
      "f  \n",
      "g  \n",
      "h e\n",
      "i n\n",
      "j h\n",
      "k  \n",
      "l i\n",
      "m e\n",
      "n  \n",
      "o u\n",
      "p l\n",
      "q  \n",
      "r  \n",
      "s  \n",
      "t h\n",
      "u t\n",
      "v e\n",
      "w a\n",
      "x t\n",
      "y  \n",
      "z y\n",
      "  t\n"
     ]
    }
   ],
   "source": [
    "for l in random_idx.alphabet:\n",
    "    lidx = np.argmax(predict_from_2grams(l))\n",
    "    print l, random_idx.alphabet[lidx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a lot of letters tend to have space after them. 'q' has space somehow, figured it would be 'u'. 't' following space is the most typical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.load('data/alice-3gram-space-d50K-160223.npz')\n",
    "letter_vectors_3g = h['letter_vectors']\n",
    "hyperdictionary_3g = np.squeeze(h['hyperdictionary'].T)\n",
    "\n",
    "N = hyperdictionary_3g.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i wasnt asleep he sa i i\n",
      "nobody asked your op i e\n",
      "are their heads off  s t\n",
      "why did they live at    \n",
      "the king looked anxi o h\n",
      "a cheap sort of pres e  \n",
      "ill be         judge   t\n",
      "once more she found  h t\n",
      "lets go on with the  g t\n",
      "why did they live at    \n",
      "i do hope itll make  m t\n",
      "you mean you cant ta k n\n",
      "what do you know abo u u\n",
      "lets go on with the  g t\n",
      "whos making personal   i\n",
      "thats nothing to wha t t\n",
      "are you content now  s  \n",
      "we indeed cried the  m t\n",
      "how fond she is of f i o\n",
      "you must remember re m  \n",
      "there was not a mome n  \n",
      "copyright laws in mo s u\n",
      "i cant tell you just    \n",
      "it was the best butt e e\n",
      "i wonder what i shou l  \n",
      "it is a long tail ce r  \n",
      "oh youre sure to do  t i\n",
      "stupid things alice  b t\n",
      "except for the limit e  \n",
      "oh do let me help to    \n",
      "i must go and get re a  \n",
      "alice went timidly u p p\n",
      "she said this last w o a\n",
      "and she went on plan n d\n",
      "but if im not the sa m i\n",
      "you must remember re m  \n",
      "but her sister sat s t h\n",
      "you know what to bea u d\n",
      "if you wish to charg e e\n",
      "then you know the mo c u\n",
      "come my heads free a t n\n",
      "and the moral of tha t t\n",
      "how queer it seems a l n\n",
      "who stole the tarts    a\n",
      "i think that will be   r\n",
      "and the gryphon adde d r\n",
      "yes said alice we le a  \n",
      "what never heard of  u t\n",
      "very much indeed sai d d\n",
      "do not unlink or det a  \n",
      "is that all said ali c c\n",
      "to learn more about  t t\n",
      "org  for additional  c t\n",
      "he was an old crab h e e\n",
      "well thought alice t o h\n",
      "despite these effort s n\n",
      "wow wow wow  here yo u u\n",
      "in another moment do w  \n",
      "in another moment do w  \n",
      "tut tut child said t h h\n",
      "i can see youre tryi n n\n",
      "herald read the accu s c\n",
      "the foundations prin c g\n",
      "well i should like t o h\n",
      "please maam is this  n a\n",
      "are their heads off  s t\n",
      "very soon the rabbit    \n",
      "it is a long tail ce r  \n",
      "first however she wa i s\n",
      "you advance twice  e a x\n",
      "come            ill  t t\n",
      "indemnity  you agree    \n",
      "they were just begin n g\n",
      "it quite makes my fo r r\n",
      "what is it  the gryp h a\n",
      "the cats head began  f a\n",
      "volunteers and finan c d\n",
      "alice was very glad  t t\n",
      "im glad they dont gi v v\n",
      "then you know the mo c u\n",
      "you ought to be asha m t\n",
      "just then she heard  s t\n",
      "or next day maybe th e e\n",
      "but what am i to do  s i\n",
      "she felt very curiou s  \n",
      "the cat seemed to th i e\n",
      "silence all round if    \n",
      "i mean what makes th e e\n",
      "come lets try the fi r r\n",
      "alice crouched down  a a\n",
      "i never saw one or h e e\n",
      "they were learning t o h\n",
      "if you do not charge   t\n",
      "redistribution is su b r\n",
      "and shes such a capi t j\n",
      "well then the grypho n u\n",
      "do not copy display  p t\n",
      "i wasnt asleep he sa i i\n",
      "at last the mouse wh o i\n",
      "the judge by the way    \n",
      "0.32\n"
     ]
    }
   ],
   "source": [
    "def predict_from_3grams(sentence):\n",
    "    letters = sentence[-2:]\n",
    "    subvec = np.ones(N)\n",
    "    \n",
    "    for letter in letters:\n",
    "        letter_idx = random_idx.alphabet.find(letter)\n",
    "        subvec = np.roll(subvec, 1) * letter_vectors_3g[letter_idx,:]\n",
    "        \n",
    "    subvec = np.roll(subvec, 1)\n",
    "\n",
    "    val = np.dot(letter_vectors_3g/N, subvec*hyperdictionary_3g)\n",
    "    \n",
    "    return val\n",
    "\n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_3grams)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also works fairly well. pretty good about 'the' and short words.\n",
    "\n",
    "Now, we can see the whole 3-gram prediction structure as a matrix. The first letter will be on the left, and the second on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  a b c d e f g h i j k l m n o p q r s t u v w x y z  \n",
      "a r o k   x t e i d p e i e d c p u e     t e z o     t\n",
      "b c u q o r h x x p f d e x j u h a j d r t h z s d m w\n",
      "c n   m o   i x   i m   e t   u d j e l   c n k p r p y\n",
      "d t g h h r u m g z   z y h z   g p t k c c   p   f v t\n",
      "e d o t     r z a r   n f x   j i w       d e e t   f t\n",
      "f z i m s n w y i r p n k r   r b v r d e q q u i o o t\n",
      "g v x t   t o l t v y t a z p a i j e   x     v s r z t\n",
      "h t b c r   t p q n q i v i x u y c i b   h g v u m r s\n",
      "i z u e   d   h p w j e l   g n f v d     t l t h l p g\n",
      "j     p r c b g t x h d t v c f k p a   t s t h p k m x\n",
      "k q j x j   q k x n u f y   n b e m v m j y e n u h l t\n",
      "l r j r       z q c k u   s b o u a a w a k k q e   u t\n",
      "m k l l h   l y h n y a y h r u v n m   s s m t x w d o\n",
      "n s e e     z   f n a i y u i w y   r     g q m     q a\n",
      "o t w k g x   r r y p v g e   k e t   b     e   b c t i\n",
      "p t m b e r g c f j y n a e v x e p o s z w u l u g e c\n",
      "q u b u c p y o y b b r z z   y e w x d d e j p g o a j\n",
      "r i w q     q e o g   l d   j j y l o   n e g d     i t\n",
      "s i j d c   n   e d t v y x t   j e m     r u c g g k a\n",
      "t n k y o r m v e n   x e c s   x g r   e r i e l   g t\n",
      "u i l h b e k h y s k y d z d i   d   e   q u j g b e s\n",
      "v h u u q r b n s n g h p u q i a g z c a   t e b e i c\n",
      "w s w k e r d o i t c x f k   r i l i n t i k z n s u  \n",
      "x f x w a e d l o h x g x f j n j k b l l q w q x l x q\n",
      "y r e v w c m v d n r c g g q u a d p e h   w a l x u t\n",
      "z y t o z a i a f h p g f   b k f w w h y r j n x b l s\n",
      "  n e o o x o r e t u i i a o f r u e h h p e a d o z  \n"
     ]
    }
   ],
   "source": [
    "print\n",
    "print ' ',\n",
    "for l in random_idx.alphabet:\n",
    "    print l,    \n",
    "print\n",
    "\n",
    "for l in random_idx.alphabet:\n",
    "    print l,\n",
    "    for j in random_idx.alphabet:\n",
    "        lidx = np.argmax(predict_from_3grams(l+j))\n",
    "        print random_idx.alphabet[lidx],\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
