{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alice in Wonderland Hyperdictionary Prediction\n",
    "\n",
    "I am creating a pipeline for testing predictions. I am going to compare different strategies and try and predict the next letter given a sentence from alice and 20 characters within that sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n",
      "2016-02-23 21:17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random_idx\n",
    "import utils\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdict = open(\"raw_texts/texts_english/alice_in_wonderland.txt\")\n",
    "text = fdict.read()\n",
    "\n",
    "sentences = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1207"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the function to run the test. This takes in a prediction function, gives it a sentence and asks the function to predict the next letter. Right now, I have the prediction_func return a histogram of letters, but the test_prediction just takes the maximum. Guy was talking about measuring entropy reduction, which is probably a better metric, but this is just a first pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_prediction(prediction_func, lookback=20):\n",
    "    \n",
    "    # We're doing all this just to make sure the sentence is long enough\n",
    "    for i in range(100):\n",
    "        sentence_str = sentences[np.random.randint(len(sentences))].lower()\n",
    "        \n",
    "        if len(sentence_str) <= lookback:\n",
    "            continue\n",
    "        \n",
    "        sidx = np.random.randint(len(sentence_str) - lookback)\n",
    "        \n",
    "        rm = string.punctuation + string.digits\n",
    "    \n",
    "        for p in string.punctuation:\n",
    "            sentence_str = sentence_str.replace(p, '')\n",
    "        \n",
    "        sentence_str = sentence_str.replace('\\n',' ')\n",
    "        sentence_str = sentence_str.replace('\\r','')\n",
    "        sentence_str = sentence_str.replace('\\t','')\n",
    "        sentence_str = sentence_str.strip()\n",
    "        \n",
    "        if len(sentence_str[sidx:]) > lookback:\n",
    "            break\n",
    "            \n",
    "\n",
    "    \n",
    "    # ok, so ask for the next letter\n",
    "    next_letter_dist = prediction_func(sentence_str[:lookback])\n",
    "    \n",
    "    # just take the argmax for now.\n",
    "    pred_lidx = np.argmax(next_letter_dist)\n",
    "    \n",
    "    corr_letter = sentence_str[lookback]\n",
    "    corr_lidx = random_idx.alphabet.find(corr_letter)\n",
    "    \n",
    "    # output to analyze performance\n",
    "    print sentence_str[:lookback], random_idx.alphabet[corr_lidx], random_idx.alphabet[pred_lidx]\n",
    "    \n",
    "    return corr_lidx == pred_lidx\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always Guess 'e'\n",
    "\n",
    "The first thing to try is to just guess 'e' every time. Let's see how that does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def always_predict_e(sentence):\n",
    "    letter_hist = zeros(len(random_idx.alphabet))\n",
    "    \n",
    "    letter_hist[4] = 1\n",
    "    \n",
    "    return letter_hist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it doesnt look like  o e\n",
      "it looked goodnature d e\n",
      "the dormouse is asle e e\n",
      "there is another sho r e\n",
      "only i dont think al i e\n",
      "you dont know much s a e\n",
      "ive seen hatters bef o e\n",
      "thus we do not neces s e\n",
      "the kings argument w a e\n",
      "no no the adventures   e\n",
      "do you play croquet  w e\n",
      "where shall i begin  p e\n",
      "when the procession  c e\n",
      "well thought alice t o e\n",
      "alice said but was d r e\n",
      "volunteers and finan c e\n",
      "its no use speaking  t e\n",
      "it was opened by ano t e\n",
      "please maam is this  n e\n",
      "just at this moment  a e\n",
      "i dont see said the  c e\n",
      "i neednt be afraid o f e\n",
      "it doesnt look like  o e\n",
      "after a time she hea r e\n",
      "edwin and morcar the   e\n",
      "ill put a stop to th i e\n",
      "and yet i dont know  h e\n",
      "org111    updated ed i e\n",
      "youre nothing but a  p e\n",
      "alice crouched down  a e\n",
      "the fishfootman bega n e\n",
      "lets go on with the  g e\n",
      "and then turning to  t e\n",
      "he unfolded the pape r e\n",
      "and she began thinki n e\n",
      "the king laid his ha n e\n",
      "you must be said the   e\n",
      "collar that dormouse   e\n",
      "it was no doubt only   e\n",
      "you can easily compl y e\n",
      "alice looked at the  j e\n",
      "no please go on alic e e\n",
      "lets go on with the  g e\n",
      "as there seemed to b e e\n",
      "alice said but was d r e\n",
      "start full license     e\n",
      "a knot said alice al w e\n",
      "alice waited a littl e e\n",
      "alice did not quite  l e\n",
      "i beg pardon your ma j e\n",
      "most people start at   e\n",
      "thats enough about l e e\n",
      "if thats all you kno w e\n",
      "and she squeezed her s e\n",
      "thinking again the d u e\n",
      "if you received the  w e\n",
      "there was nothing so   e\n",
      "and certainly there  w e\n",
      "does the boots and s h e\n",
      "twinkle twinkle  her e e\n",
      "there are a lot of t h e\n",
      "it is a very good he i e\n",
      "its all about as cur i e\n",
      "then followed the kn a e\n",
      "as soon as she was s m e\n",
      "she got up and went  t e\n",
      "but youre so easily  o e\n",
      "the cat seemed to th i e\n",
      "i dare say youre won d e\n",
      "please would you tel l e\n",
      "and she thought of h e e\n",
      "as that is rather a  h e\n",
      "presently she began  a e\n",
      "give your evidence s a e\n",
      "what day of the mont h e\n",
      "exactly so said the  h e\n",
      "does the boots and s h e\n",
      "first she tried to l o e\n",
      "come on  everybody s a e\n",
      "so she went in searc h e\n",
      "however it was over  a e\n",
      "are you to get in at   e\n",
      "and as you might lik e e\n",
      "it was the white rab b e\n",
      "alice heard it say t o e\n",
      "she went in without  k e\n",
      "and yet i wish i cou l e\n",
      "you advance twice  e a e\n",
      "why what are your sh o e\n",
      "i only wish people k n e\n",
      "if an individual pro j e\n",
      "even the duchess sne e e\n",
      "first came ten soldi e e\n",
      "would you tell me sa i e\n",
      "yes thats it said th e e\n",
      "i never knew so much   e\n",
      "its a friend of mine a e\n",
      "this piece of rudene s e\n",
      "there was nothing el s e\n",
      "nobody asked your op i e\n",
      "0.11\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "iscorrect_prediction = zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "    iscorrect_prediction[i] = test_prediction(always_predict_e)\n",
    "    \n",
    "print np.mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can get about 10-15% of the next letter guesses correct by just guessing 'e' every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Dictionary\n",
    "\n",
    "A pretty sensible method of predicting the next letter is to use an external dictionary and try and base the guess on the last word. This external dictionary is created from the '2of12id.txt' dictionary, but only contains a subset of the full word list. This dictionary also includes every substring of the word, as well as spaces -- the full word contains a space at the end. This way it can guess space. This dictionary is naive to any of the statistics of the word appearance, and will just guess based on what is possible and not what is most likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.load('data/hyperdictionary_external-s20-d1M-160223.npz')\n",
    "letter_vectors_substr = h['letter_vectors']\n",
    "hyperdictionary_substr = h['hyperdictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ive read that in som e a\n",
      "alice thought this a   n\n",
      "the cat only grinned   i\n",
      "you promised to tell   s\n",
      "there was no label t h a\n",
      "there were doors all   y\n",
      "once more she found  h t\n",
      "of course you dont t h a\n",
      "when she got back to   l\n",
      "i keep them to sell  t t\n",
      "tell us a story said    \n",
      "the first thing ive  g t\n",
      "the mock turtles sto r p\n",
      "only i dont think al i p\n",
      "thank you said alice   g\n",
      "as that is rather a  h t\n",
      "and she began thinki n k\n",
      "ill put a stop to th i r\n",
      "i told you butter wo u o\n",
      "dinahll miss me very   a\n",
      "you dont know much s a c\n",
      "org  for additional  c t\n",
      "yes said alice we le a s\n",
      "the copyright laws o f o\n",
      "it isnt mine said th e r\n",
      "oh youre sure to do  t t\n",
      "he had been looking  a t\n",
      "are their heads off  s t\n",
      "the master was an ol d i\n",
      "what day of the mont h a\n",
      "please would you tel l e\n",
      "here come and help m e y\n",
      "org  for additional  c t\n",
      "if it had grown up s h c\n",
      "collar that dormouse   q\n",
      "alice began to feel  v t\n",
      "of course not said t h a\n",
      "and how many hours a   n\n",
      "i havent opened it y e a\n",
      "everythings got a mo r u\n",
      "that you wont though t a\n",
      "theres certainly too   t\n",
      "a caucusrace and a l o o\n",
      "explain all that sai d l\n",
      "the door led right i n l\n",
      "what a number of cuc u h\n",
      "oh please mind what  y t\n",
      "ive a right to think   b\n",
      "if you didnt sign it   a\n",
      "but what happens whe n r\n",
      "let me see that woul d d\n",
      "let me alone  serpen t x\n",
      "limited warranty dis c g\n",
      "is that the reason s o c\n",
      "i quite agree with y o a\n",
      "are you content now  s t\n",
      "i deny it said the m a y\n",
      "nothing can be clear e e\n",
      "the end      end of  p t\n",
      "oh i beg your pardon   l\n",
      "advice from a caterp i z\n",
      "however she did not  l t\n",
      "it isnt directed at  a t\n",
      "this time there coul d y\n",
      "there was nothing el s i\n",
      "here the queen put o n o\n",
      "i must go and get re a m\n",
      "i suppose youll be t e a\n",
      "which would not be a n n\n",
      "very uncomfortable f o i\n",
      "alice thought to her s e\n",
      "there was no one two   p\n",
      "theres plenty of roo m m\n",
      "its the oldest rule  i t\n",
      "first came ten soldi e a\n",
      "no i give it up alic e y\n",
      "stuff and nonsense s a c\n",
      "would it be of any u s r\n",
      "alice laughed so muc h k\n",
      "but she waited patie n n\n",
      "at last the mouse wh o a\n",
      "but who is to give t h a\n",
      "what is it  the gryp h u\n",
      "one of the jurors ha d s\n",
      "never said the queen   h\n",
      "most people start at   e\n",
      "do not unlink or det a o\n",
      "first she tried to l o o\n",
      "do not charge a fee  f t\n",
      "alice crouched down  a t\n",
      "please your majesty  s t\n",
      "well ive often seen  a t\n",
      "you might just as we l a\n",
      "yes but some crumbs  m t\n",
      "it is a very good he i s\n",
      "pray dont trouble yo u d\n",
      "if you do not charge   d\n",
      "alice remained looki n q\n",
      "off with her head th e r\n",
      "are you to get in at   e\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "N = hyperdictionary_substr.shape[0]\n",
    "\n",
    "def predict_from_last_word(sentence):\n",
    "    \n",
    "    if sentence[-1] == ' ':\n",
    "        letter_hist = zeros(len(random_idx.alphabet))\n",
    "        # guess 't' if it is a space at the end\n",
    "        t_idx = random_idx.alphabet.find('t')\n",
    "        letter_hist[t_idx] = 1\n",
    "        return letter_hist\n",
    "    else:\n",
    "        # find the last space in the sentence\n",
    "        words = sentence.split()\n",
    "\n",
    "        last_word = words[-1]    \n",
    "\n",
    "        subword = ''\n",
    "        subvec = np.ones(N)\n",
    "        for i,letter in enumerate(last_word):\n",
    "            letter_idx = random_idx.alphabet.find(letter)\n",
    "            subvec = np.roll(subvec, 1) * letter_vectors_substr[letter_idx,:]\n",
    "            subword += letter\n",
    "\n",
    "        subvec = np.roll(subvec, 1)\n",
    "\n",
    "        val = np.dot(letter_vectors_substr/N, subvec*hyperdictionary_substr)\n",
    "        return val\n",
    "\n",
    "        \n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary is pretty close performance-wise to just guessing 'e'. However, you can see it does a decent job when there is a long word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using internal hyperdictionary\n",
    "\n",
    "Next, I built a similar substring hyperdictionary as before, but this time I used the list of words actually from alice. This is a pretty ideal dictionary to have handy. The performance of this dictionary is useful to compare with other algorithms, as this will have a good chance of working well. If another algorithm can beat this, then it has learned a lot about english and predicting Alice, and probably has an important insight about learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.load('data/hyperdictionary_alice-d1M-160223.npz')\n",
    "letter_vectors_alice = h['letter_vectors']\n",
    "hyperdictionary_alice = h['hyperdictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice could see this    \n",
      "this seemed to alice   s\n",
      "if you paid a fee fo r r\n",
      "well be off then sai d d\n",
      "indemnity  you agree   m\n",
      "why  it does the boo t k\n",
      "let me see four time s s\n",
      "yes it is his busine s s\n",
      "i dont quite underst a a\n",
      "he denies it said th e e\n",
      "we do not solicit do n i\n",
      "he looked anxiously  o t\n",
      "she cant explain it  s t\n",
      "unimportant of cours e e\n",
      "very true said the d u r\n",
      "donations are accept e i\n",
      "very true said the d u r\n",
      "as wet as ever said  a t\n",
      "mind now the poor li t n\n",
      "additional terms wil l l\n",
      "there are a few thin g g\n",
      "thats the most impor t t\n",
      "it looked goodnature d f\n",
      "the duchess took no  n t\n",
      "once said the mock t u  \n",
      "oh i beg your pardon   e\n",
      "ive tried the roots  o t\n",
      "she felt that she wa s t\n",
      "twinkle twinkle  her e  \n",
      "and the moral of tha t n\n",
      "very said alice wher e e\n",
      "well id hardly finis h h\n",
      "it sounded an excell e e\n",
      "project gutenberg vo l l\n",
      "im a poor man your m a o\n",
      "alice thought she mi g n\n",
      "most people start at    \n",
      "a bright idea came i n m\n",
      "i dont believe it sa i i\n",
      "youll see me there s a l\n",
      "i almost wish i hadn t t\n",
      "unimportant of cours e e\n",
      "however she soon mad e  \n",
      "then she went to wor k k\n",
      "tell her about the r e o\n",
      "after a while she re m v\n",
      "she did it so quickl y y\n",
      "alice looked up and  t t\n",
      "and just as id taken    \n",
      "they were just begin n  \n",
      "theres plenty of roo m t\n",
      "take off your hat th e e\n",
      "oh there goes his pr e a\n",
      "there was a sound of    \n",
      "you advance twice  e a d\n",
      "alice replied eagerl y y\n",
      "no theyre not said t h  \n",
      "alice looked up and  t t\n",
      "now ill manage bette r r\n",
      "first came ten soldi e e\n",
      "never mind said the  k t\n",
      "most people start at    \n",
      "now ill manage bette r r\n",
      "next came an angry v o u\n",
      "redistribution is su b g\n",
      "youll see me there s a l\n",
      "alice was very nearl y y\n",
      "i dont even know wha t t\n",
      "i never saw one or h e j\n",
      "so they sat down and    \n",
      "when did you begin   t t\n",
      "what are they doing  a t\n",
      "what is it  the gryp h h\n",
      "limited right of rep l o\n",
      "yes but some crumbs  m t\n",
      "here the queen put o n l\n",
      "this here young lady    \n",
      "information about th e e\n",
      "if you received the  w t\n",
      "the mock turtles sto r c\n",
      "the mock turtles sto r c\n",
      "on this the white ra b p\n",
      "of course not said t h  \n",
      "ah then yours wasnt  a t\n",
      "she carried the pepp e e\n",
      "i quite agree with y o a\n",
      "so they got their ta i k\n",
      "youre wrong about th e e\n",
      "just about as much r i o\n",
      "alice thought she ha d i\n",
      "but about his toes t h  \n",
      "they may be modified    \n",
      "would not could not  w t\n",
      "give your evidence s a l\n",
      "you provide in accor d d\n",
      "oh hush the rabbit w h a\n",
      "however this bottle  w t\n",
      "at last the mouse wh o o\n",
      "the mouse gave a sud d d\n",
      "however when they ha d i\n",
      "0.44\n"
     ]
    }
   ],
   "source": [
    "N = hyperdictionary_alice.shape[0]\n",
    "\n",
    "def predict_from_last_word(sentence):\n",
    "    \n",
    "    if sentence[-1] == ' ':\n",
    "        letter_hist = zeros(len(random_idx.alphabet))\n",
    "        # guess 't' if it is a space at the end\n",
    "        t_idx = random_idx.alphabet.find('t')\n",
    "        letter_hist[t_idx] = 1\n",
    "        return letter_hist\n",
    "    else:\n",
    "        # find the last space in the sentence\n",
    "        words = sentence.split()\n",
    "\n",
    "        last_word = words[-1]    \n",
    "\n",
    "        subword = ''\n",
    "        subvec = np.ones(N)\n",
    "        for i,letter in enumerate(last_word):\n",
    "            letter_idx = random_idx.alphabet.find(letter)\n",
    "            subvec = np.roll(subvec, 1) * letter_vectors_alice[letter_idx,:]\n",
    "            subword += letter\n",
    "\n",
    "        subvec = np.roll(subvec, 1)\n",
    "\n",
    "        val = np.dot(letter_vectors_alice/N, subvec*hyperdictionary_alice)\n",
    "        return val\n",
    "\n",
    "        \n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dont like the look   i\n",
      "the players all play e e\n",
      "the jury all brighte n n\n",
      "said the mock turtle    \n",
      "that was a narrow es c q\n",
      "i wonder if i shall  f t\n",
      "you can easily compl y i\n",
      "back to land again a n m\n",
      "the queen smiled and    \n",
      "after a minute or tw o e\n",
      "after that continued    \n",
      "just then she heard  s t\n",
      "the queens croquetgr o g\n",
      "still she went on gr o y\n",
      "if i or she should c h r\n",
      "and what are they ma d d\n",
      "donations are accept e i\n",
      "does your watch tell   s\n",
      "compliance requireme n n\n",
      "alice did not quite  k t\n",
      "pig and pepper  for  a t\n",
      "down the rabbithole    t\n",
      "one side of what the   m\n",
      "mine is a long and a   m\n",
      "at any rate ill neve r r\n",
      "what are you thinkin g g\n",
      "in another minute th e e\n",
      "this was such a new  i t\n",
      "very uncomfortable f o e\n",
      "alice did not at all    \n",
      "alice kept her eyes  a t\n",
      "hart is the originat o o\n",
      "these were the verse s  \n",
      "off with her head th e e\n",
      "redistribution is su b g\n",
      "oh dont talk about t r  \n",
      "youll see me there s a l\n",
      "what is his sorrow s h l\n",
      "why she of course sa i i\n",
      "alice thought the wh o o\n",
      "even the duchess sne e e\n",
      "but what am i to do  s t\n",
      "mine is a long and a   m\n",
      "why said the caterpi l l\n",
      "stolen the king excl a a\n",
      "what do you know abo u u\n",
      "the trial cannot pro c m\n",
      "at last the dodo sai d d\n",
      "its the oldest rule  i t\n",
      "said i could not swi m m\n",
      "theres no such thing    \n",
      "many small donations    \n",
      "but if im not the sa m i\n",
      "does the boots and s h l\n",
      "so they had to fall  a t\n",
      "they all can said th e e\n",
      "what is it  the gryp h h\n",
      "i want a clean cup i n m\n",
      "stand up and repeat  t t\n",
      "not at first perhaps    \n",
      "well then the cat we n  \n",
      "3 a full refund of a n m\n",
      "after these came the   m\n",
      "and shes such a capi t t\n",
      "the caterpillar was  t t\n",
      "tut tut child said t h  \n",
      "right as usual said  t t\n",
      "as soon as the jury  h t\n",
      "i keep them to sell  t t\n",
      "oh dont talk about t r  \n",
      "theres a porpoise cl o a\n",
      "alice led the way an d y\n",
      "alice was very nearl y y\n",
      "there is another sho r w\n",
      "the miserable hatter   s\n",
      "zip  this and all as s l\n",
      "you ought to be asha m m\n",
      "not quite right im a f m\n",
      "london is the capita l l\n",
      "now we shall get on  b t\n",
      "youre thinking about    \n",
      "it isnt directed at  a t\n",
      "of course the mock t u  \n",
      "i should like to hea r p\n",
      "an arm you goose who   l\n",
      "a barrowful of what  t t\n",
      "its the stupidest te a n\n",
      "a likely story indee d d\n",
      "and so it was indeed    \n",
      "i shall sit here he  s t\n",
      "if an individual wor k k\n",
      "and now which is whi c t\n",
      "dont let him know sh e i\n",
      "treacle said the dor m m\n",
      "i dont quite underst a a\n",
      "i shall be punished  f t\n",
      "there was not a mome n n\n",
      "you are not attendin g g\n",
      "if an individual pro j m\n",
      "theres a porpoise cl o a\n",
      "0.43\n"
     ]
    }
   ],
   "source": [
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.load('data/hyperdictionary_alice-short-d1M-160223.npz')\n",
    "letter_vectors_short = h['letter_vectors']\n",
    "hyperdictionary_short = h['hyperdictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you must remember re m e\n",
      "if you are redistrib u n\n",
      "its a pun the king a d n\n",
      "of course it is said    \n",
      "the march hare took  t t\n",
      "how the creatures or d  \n",
      "what a number of cuc u u\n",
      "the hatter shook his    \n",
      "it all came differen t t\n",
      "you comply with all  o t\n",
      "did you say what a p i a\n",
      "theyre done with bla c d\n",
      "however it was over  a t\n",
      "i never heard of ugl i i\n",
      "let me alone  serpen t t\n",
      "and shes such a capi t t\n",
      "but its no use now t h w\n",
      "if you dont know wha t t\n",
      "alice thought the wh o o\n",
      "you must require suc h h\n",
      "anything you like sa i y\n",
      "that i cant remember    \n",
      "do not charge a fee  f t\n",
      "all this time the qu e e\n",
      "i believe i can gues s s\n",
      "she hastily put down    \n",
      "dinahll miss me very    \n",
      "after a while she re m e\n",
      "alice did not quite  l t\n",
      "i dare say youre won d  \n",
      "i dare say youre won d  \n",
      "and the gryphon neve r r\n",
      "how fond she is of f i l\n",
      "i never heard of ugl i i\n",
      "i should like to hea r p\n",
      "anything you like sa i y\n",
      "now i give you fair  w t\n",
      "poor little thing sa i y\n",
      "this here young lady    \n",
      "not at all said alic e e\n",
      "they must go by the  c t\n",
      "the miserable hatter   s\n",
      "which he certainly d i o\n",
      "and the moral of tha t n\n",
      "i quite forgot you d i o\n",
      "alice crouched down  a t\n",
      "and she thought of h e j\n",
      "im afraid i dont kno w c\n",
      "here the queen put o n  \n",
      "i wonder what theyll    \n",
      "how am i to get in a s n\n",
      "do you take me for a   n\n",
      "stolen the king excl a a\n",
      "donations are accept e a\n",
      "sentence firstverdic t c\n",
      "as that is rather a  h t\n",
      "indemnity  you agree    \n",
      "off with his head sh e e\n",
      "its business office  i t\n",
      "then the dormouse sh a e\n",
      "shall we try another    \n",
      "the foundation makes    \n",
      "the person or entity   b\n",
      "if thats all you kno w c\n",
      "you couldnt have wan t d\n",
      "so long as i get som e e\n",
      "the three soldiers w a h\n",
      "next came the guests    \n",
      "the dormouse had clo s s\n",
      "well be off then sai d d\n",
      "the rabbit sends in  a t\n",
      "i beg pardon your ma j g\n",
      "if you dont know wha t t\n",
      "who cares for you sa i y\n",
      "you agree that the f o l\n",
      "general information  a t\n",
      "i think i should und e o\n",
      "do you mean that you   r\n",
      "thats enough about l e o\n",
      "its the stupidest te a e\n",
      "unless you have remo v v\n",
      "it doesnt look like  o t\n",
      "i wasnt asleep he sa i y\n",
      "once upon a time the r s\n",
      "who are you said the   s\n",
      "how surprised hell b e u\n",
      "here one of the guin e e\n",
      "no i give it up alic e e\n",
      "then the queen left  o t\n",
      "id rather finish my  t t\n",
      "all right so far sai d d\n",
      "or next day maybe th e r\n",
      "perhaps it hasnt one   s\n",
      "you can easily compl y e\n",
      "one side of what the   s\n",
      "he unfolded the pape r r\n",
      "it was much pleasant e  \n",
      "yes said alice we le a f\n",
      "she took down a jar  f t\n",
      "who is it directed t o w\n",
      "0.37\n"
     ]
    }
   ],
   "source": [
    "N = hyperdictionary_short.shape[0]\n",
    "\n",
    "def predict_from_last_word(sentence):\n",
    "    \n",
    "    if sentence[-1] == ' ':\n",
    "        letter_hist = zeros(len(random_idx.alphabet))\n",
    "        # guess 't' if it is a space at the end\n",
    "        t_idx = random_idx.alphabet.find('t')\n",
    "        letter_hist[t_idx] = 1\n",
    "        return letter_hist\n",
    "    else:\n",
    "        # find the last space in the sentence\n",
    "        words = sentence.split()\n",
    "\n",
    "        last_word = words[-1]    \n",
    "\n",
    "        subword = ''\n",
    "        subvec = np.ones(N)\n",
    "        for i,letter in enumerate(last_word):\n",
    "            letter_idx = random_idx.alphabet.find(letter)\n",
    "            subvec = np.roll(subvec, 1) * letter_vectors_short[letter_idx,:]\n",
    "            subword += letter\n",
    "\n",
    "        subvec = np.roll(subvec, 1)\n",
    "\n",
    "        val = np.dot(letter_vectors_short/N, subvec*hyperdictionary_short)\n",
    "        return val\n",
    "\n",
    "        \n",
    "\n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_last_word)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using N-Grams for prediction\n",
    "\n",
    "So, now I made dictionaries that go through the alice text and look at all n-grams, including 'space' as a character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = np.load('data/alice-2gram-space-d20K-160223.npz')\n",
    "letter_vectors_2g = h['letter_vectors']\n",
    "hyperdictionary_2g = h['hyperdictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = hyperdictionary_2g.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ah then yours wasnt  a t\n",
      "these words were fol l i\n",
      "oh dear what nonsens e  \n",
      "theyre done with bla c n\n",
      "they very soon came  u t\n",
      "and the moral of tha t n\n",
      "it sounded an excell e i\n",
      "do not copy display  p t\n",
      "you mean you cant ta k n\n",
      "in another minute th e e\n",
      "i think that will be    \n",
      "if you do not charge    \n",
      "im a poor man your m a e\n",
      "they had a large can v  \n",
      "the players all play e  \n",
      "any alternate format   h\n",
      "then followed the kn a  \n",
      "he took me for his h o e\n",
      "call the next witnes s  \n",
      "the reason is said t h h\n",
      "he sent them word i  h t\n",
      "stuff and nonsense s a  \n",
      "so they got their ta i n\n",
      "right as usual said  t t\n",
      "im glad they dont gi v n\n",
      "except for the limit e h\n",
      "there was no label t h h\n",
      "let me see that woul d i\n",
      "nobody asked your op i  \n",
      "edwin and morcar the    \n",
      "no ill look first sh e e\n",
      "i do hope itll make  m t\n",
      "but i dont want to g o  \n",
      "i never went to him  t t\n",
      "hearthrug          n e  \n",
      "i never knew so much   e\n",
      "he moved on as he sp o  \n",
      "why she of course sa i n\n",
      "alice was very glad  t t\n",
      "only mustard isnt a  b t\n",
      "yes it is his busine s  \n",
      "sentence firstverdic t e\n",
      "i can tell you more  t t\n",
      "you agree that the f o  \n",
      "and what are they ma d n\n",
      "it was this last rem a e\n",
      "project gutenberg is    \n",
      "if you wish to charg e  \n",
      "how can i have done  t t\n",
      "alice did not much l i i\n",
      "theyre putting down  t t\n",
      "by reading or using  a t\n",
      "alice said but was d r  \n",
      "alice knew it was th e e\n",
      "what is a caucusrace    \n",
      "3 this work is provi d n\n",
      "there was a sound of    \n",
      "i never heard of ugl i i\n",
      "please check the pro j  \n",
      "while she was lookin g  \n",
      "well if i must i mus t  \n",
      "well perhaps you hav e e\n",
      "im glad ive seen tha t n\n",
      "however she soon mad e  \n",
      "she had just succeed e  \n",
      "write that down the  k t\n",
      "how should i know sa i n\n",
      "whoever lives there  t t\n",
      "tut tut child said t h h\n",
      "of course it is said    \n",
      "never said the queen    \n",
      "exactly so said the  h t\n",
      "we called him tortoi s n\n",
      "all right said the c a e\n",
      "i dont even know wha t n\n",
      "hearthrug          n e  \n",
      "the further off from   e\n",
      "or would you like th e e\n",
      "as wet as ever said  a t\n",
      "ahem said the mouse  w t\n",
      "what never heard of  u t\n",
      "information about do n  \n",
      "poor alice it was as    \n",
      "so she began o mouse    \n",
      "and just as id taken    \n",
      "there was nothing so    \n",
      "he looked at the gry p  \n",
      "please would you tel l i\n",
      "an invitation from t h h\n",
      "they may be modified    \n",
      "some of the birds hu r t\n",
      "im getting tired of  t t\n",
      "next came the guests    \n",
      "and the moral of tha t n\n",
      "will you wont you wi l n\n",
      "nearly all the indiv i e\n",
      "no ill look first sh e e\n",
      "id rather finish my  t t\n",
      "it must have been th a e\n",
      "ive tried the roots  o t\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "def predict_from_2grams(sentence):\n",
    "    letter = sentence[-1]\n",
    "    subvec = np.ones(N)\n",
    "    \n",
    "    letter_idx = random_idx.alphabet.find(letter)\n",
    "    subvec = np.roll(subvec, 1) * letter_vectors_2g[letter_idx,:]\n",
    "    subvec = np.roll(subvec, 1)\n",
    "\n",
    "    val = np.dot(letter_vectors_2g/N, subvec*hyperdictionary_2g)\n",
    "    \n",
    "    return val\n",
    "\n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_2grams)\n",
    "       \n",
    "print mean(iscorrect_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the 2-grams works fairly well. We can just see what it will predict for each letter, since it is only based on the last letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a n\n",
      "b e\n",
      "c e\n",
      "d  \n",
      "e  \n",
      "f  \n",
      "g  \n",
      "h e\n",
      "i n\n",
      "j w\n",
      "k i\n",
      "l i\n",
      "m e\n",
      "n  \n",
      "o  \n",
      "p  \n",
      "q u\n",
      "r  \n",
      "s  \n",
      "t h\n",
      "u t\n",
      "v e\n",
      "w h\n",
      "x y\n",
      "y  \n",
      "z d\n",
      "  t\n"
     ]
    }
   ],
   "source": [
    "for l in random_idx.alphabet:\n",
    "    lidx = np.argmax(predict_from_2grams(l))\n",
    "    print l, random_idx.alphabet[lidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.load('data/alice-3gram-space-d20K-160223.npz')\n",
    "letter_vectors_3g = h['letter_vectors']\n",
    "hyperdictionary_3g = h['hyperdictionary']\n",
    "\n",
    "N = hyperdictionary_3g.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you received the  w s\n",
      "well id hardly finis h  \n",
      "i never saw one or h e e\n",
      "a knot said alice al w i\n",
      "williams conduct at  f t\n",
      "a bright idea came i n t\n",
      "as soon as she had m a o\n",
      "and she squeezed her s  \n",
      "collar that dormouse    \n",
      "thats very important    \n",
      "come on then roared  t t\n",
      "you may copy it give   r\n",
      "alice began to feel  v s\n",
      "oh you cant help tha t t\n",
      "first it marked out  a t\n",
      "alice looked at the  j s\n",
      "if an individual pro j u\n",
      "come back the caterp i s\n",
      "come            ill  t s\n",
      "by reading or using  a t\n",
      "then the words dont  f t\n",
      "how surprised hell b e e\n",
      "we must burn the hou s  \n",
      "well i never heard i t t\n",
      "they all made a rush   e\n",
      "exactly so said the  h s\n",
      "back to land again a n n\n",
      "the first thing she  h s\n",
      "you insult me by tal k i\n",
      "alice went timidly u p c\n",
      "you may copy it give   r\n",
      "why what are your sh o e\n",
      "hand it over here sa i i\n",
      "off with her head th e e\n",
      "explain all that sai d d\n",
      "the project gutenber g  \n",
      "but its volunteers a n n\n",
      "and as you might lik e v\n",
      "7 or obtain permissi o n\n",
      "stupid things alice  b s\n",
      "who stole the tarts    a\n",
      "and the executioner  w a\n",
      "just at this moment  a t\n",
      "imagine her surprise    \n",
      "what do you mean by  t a\n",
      "does the boots and s h h\n",
      "that was a narrow es c  \n",
      "the further off from   e\n",
      "it must have been th a e\n",
      "there was nothing el s a\n",
      "and she thought of h e e\n",
      "now if you only kept   c\n",
      "dont grunt said alic e e\n",
      "you agree that you h a e\n",
      "information about th e e\n",
      "shy they seem to put    \n",
      "here was another puz z y\n",
      "well i cant show it  y t\n",
      "thats very important    \n",
      "and what are they ma d r\n",
      "off with her head th e e\n",
      "what is it  the gryp h o\n",
      "i know what it means   j\n",
      "this of course alice    \n",
      "london is the capita l t\n",
      "she was a little ner v  \n",
      "would you like to se e  \n",
      "of course we hope th a e\n",
      "youll see me there s a h\n",
      "alice could think of    \n",
      "yes but i grow at a  r s\n",
      "let me see four time s  \n",
      "i do hope itll make  m s\n",
      "never said the queen    \n",
      "you must require suc h h\n",
      "no theyre not said t h h\n",
      "go on with the next  v t\n",
      "start full license      \n",
      "explain yourself  i  c d\n",
      "alice looked at the  j s\n",
      "who cares for you sa i i\n",
      "what is his sorrow s h h\n",
      "i never heard of ugl i q\n",
      "is that all said ali c c\n",
      "start full license      \n",
      "what do you mean by  t a\n",
      "how am i to get in s h h\n",
      "i quite agree with y o o\n",
      "after a time she hea r r\n",
      "why did they live at    \n",
      "you comply with all  o s\n",
      "later editions conti n m\n",
      "now i give you fair  w a\n",
      "you are old said the    \n",
      "hardly knowing what  s t\n",
      "give your evidence t h h\n",
      "alice caught the bab y p\n",
      "the only things in t h h\n",
      "what a curious feeli n c\n",
      "dinah my dear i wish   e\n",
      "0.37\n"
     ]
    }
   ],
   "source": [
    "def predict_from_3grams(sentence):\n",
    "    letters = sentence[-2:]\n",
    "    subvec = np.ones(N)\n",
    "    \n",
    "    for letter in letters:\n",
    "        letter_idx = random_idx.alphabet.find(letter)\n",
    "        subvec = np.roll(subvec, 1) * letter_vectors_3g[letter_idx,:]\n",
    "        \n",
    "    subvec = np.roll(subvec, 1)\n",
    "\n",
    "    val = np.dot(letter_vectors_3g/N, subvec*hyperdictionary_3g)\n",
    "    \n",
    "    return val\n",
    "\n",
    "trials = 100\n",
    "iscorrect_prediction = zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    iscorrect_prediction[i] = test_prediction(predict_from_3grams)\n",
    "       \n",
    "print mean(iscorrect_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also works fairly well. pretty good about 'the' and short words.\n",
    "\n",
    "Now, we can see the whole 3-gram prediction structure as a matrix. The first letter will be on the left, and the second on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  a b c d e f g h i j k l m n o p q r s t u v w x y z  \n",
      "a b p k   k i s b d d e i e d r k k       r v o b   u s\n",
      "b c s g d   d h y t u b e b b u k b i s p t d e q   x m\n",
      "c t t y z   a q   o r   l e   n r u e q w j t w n h f m\n",
      "d s j i l a a s v n j z d k y   j l e u v i s q k   g t\n",
      "e r e j     r z o r y o a     z v v     y t e z a     s\n",
      "f c g c j y q s v f   t o x b r b f o h e j d k y a m t\n",
      "g n o s u   w h t x o p q v e a g o g s g k s l o d y t\n",
      "h t   p n   f d d n o u m m a o i x o c l g v   n n f a\n",
      "i h s e   p j h o f k v l e g n k a j     n a k q r i d\n",
      "j a c u l w z p q l d r g l c k k j i c o r j g n g i v\n",
      "k o t q b   h q i n   e r u r u l p c g g k o u w k c t\n",
      "l n o q       c i c c i   i u o a c q d d p u j g   e s\n",
      "m r h v g   t p b d f m c h n u t w t u q h a j q m x  \n",
      "n v s x     a   a c g   y d z t v h q j   k a h z   j a\n",
      "o h i i b s   p i s o e t e   k r z   t w   e   b y t t\n",
      "p i f f q a h c b e w t i x u v t d c e c c p n i e   a\n",
      "q q o   n z n v r u l f a s j l n a e   i e q u t t y m\n",
      "r v o e c   l x d m j o o o x u s e u e y   d v e   f a\n",
      "s i z f       i e n o j y i r   c h o     q h q p q s a\n",
      "t t b h m r q i e m f p e   o   v v w   e x d f k   n t\n",
      "u d n h q e a h z t c h d n f u   d e e   p o z m p y s\n",
      "v p k s y r o c g f s k c i a i v p a m f i a t b o u x\n",
      "w s l d j n w w i t u g k y   r x u k j n e g y r s h s\n",
      "x n n u t u n o r g u b i l q j b d y w i   b p d w r s\n",
      "y w s p i r y y s j v j o p r u o s q r h j m j w v z a\n",
      "z l n k s q   q j t o l l l d m p k f v c j e t a e y a\n",
      "  n e a o x i e e t f i o o o f a u a h h c e a m o v  \n"
     ]
    }
   ],
   "source": [
    "print\n",
    "print ' ',\n",
    "for l in random_idx.alphabet:\n",
    "    print l,    \n",
    "print\n",
    "\n",
    "for l in random_idx.alphabet:\n",
    "    print l,\n",
    "    for j in random_idx.alphabet:\n",
    "        lidx = np.argmax(predict_from_3grams(l+j))\n",
    "        print random_idx.alphabet[lidx],\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
